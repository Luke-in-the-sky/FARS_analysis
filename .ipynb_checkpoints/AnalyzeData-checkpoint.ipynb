{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and modules\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FARS_data_files = {2014 : 'C:\\\\Users\\\\Luke-Lenovo\\\\Desktop\\\\Database2014.txt',\n",
    "                   2013 : 'C:\\\\Users\\\\Luke-Lenovo\\\\Desktop\\\\Database2013.txt',\n",
    "                   2012 : 'C:\\\\Users\\\\Luke-Lenovo\\\\Desktop\\\\Database2012.txt',\n",
    "                   2011 : 'C:\\\\Users\\\\Luke-Lenovo\\\\Desktop\\\\Database2011.txt',\n",
    "                   2010 : 'C:\\\\Users\\\\Luke-Lenovo\\\\Desktop\\\\Database2010.txt'}\n",
    "\n",
    "def size_of_dataframe(df):\n",
    "    if type(df)==pd.core.series.Series or type(df)==pd.sparse.series.SparseSeries:\n",
    "            return (df.values.nbytes + df.index.nbytes)\n",
    "    return (df.values.nbytes + df.index.nbytes + df.columns.nbytes)\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "# ------------------\n",
    "\n",
    "# Check if files exists\n",
    "def load_file(file_):\n",
    "    print('Loading', file_, '...')\n",
    "    try:\n",
    "        df = pd.read_csv(file_, engine = 'python', sep='\\t', index_col='Obs.')\n",
    "    except OSError:\n",
    "        print('!!file not found!!', file_)\n",
    "        return np.nan\n",
    "    return df\n",
    "\n",
    "def build_dataset():\n",
    "    FARS_dataframes = {}\n",
    "    for year in FARS_data_files.keys():\n",
    "        FARS_dataframes[year] = load_file(FARS_data_files[year])\n",
    "\n",
    "    # Put them all in one dataframe\n",
    "    data = pd.concat(FARS_dataframes)#, ignore_index = True)\n",
    "\n",
    "    # Eliminate the 'Unnamed' column we got from the reading of the csv\n",
    "    for key in data.keys():\n",
    "        if key.startswith('Unnamed'):\n",
    "            data = data.drop(key, 1)\n",
    "    print('Number of rows in dataset:',len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select interesting stuff\n",
    "# --------------\n",
    "\n",
    "# Load Code manual\n",
    "import pickle\n",
    "code_manual = pickle.load( open( \"CodeManual.p\", \"rb\" ) )\n",
    "\n",
    "# Select interesting features and map them to their respective\n",
    "#   names in the code manual\n",
    "translate_column_names = {\n",
    "#'driverdrowsy' : 'Drowsy driver',\n",
    "'ptype' : 'Person Type',\n",
    "'druginv' : 'Police Reported Drug Involvement',\n",
    "'heavytruck': 'Large Truck Related',\n",
    "'schlbus' : 'School Bus Related',\n",
    "'sex' : 'Sex',\n",
    "'race' : 'Race',\n",
    "'reljuncinter' : 'Relation To Junction: Within Interchange Area',\n",
    "'atmcond': 'Atmospheric Condition (1)',\n",
    "'holiday' : 'Holiday Related',\n",
    "#'nhs' : 'National Highway System',\n",
    "'hispanic' : 'Hispanic',\n",
    "'rfun' : 'Roadway Function Class',\n",
    "'lightcond' : 'Light Condition',\n",
    "'speeding' : 'Speeding',\n",
    "'dayofweek' : 'Day Of Week',\n",
    "#'acchr' : 'Accident hour', \n",
    "#'latitude' : 'Latitude',\n",
    "#'longitude': 'Longitude'\n",
    "}\n",
    "\n",
    "also_interesting = ['age', 'alcres']\n",
    "\n",
    "labelsOfInter = list(translate_column_names.keys())\n",
    "labelsOfInter.extend(also_interesting)\n",
    "for item in['heavytruck','schlbus','reljuncinter']:\n",
    "    labelsOfInter.remove(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce dimensionality\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collapse some features values\n",
    "# ------------\n",
    "\n",
    "# Categorize on number of Fatalities\n",
    "def NumFatalitiesToCategory(num):\n",
    "    if num <3:\n",
    "        return 1\n",
    "    elif (num>=3) and (num<6):\n",
    "        return 2\n",
    "    return 3\n",
    "\n",
    "# Reduce categories in 'Light Condition'\n",
    "code_manual[translate_column_names['lightcond']][11] = 'Dawn/Dusk'\n",
    "code_manual[translate_column_names['lightcond']][12] = 'Dark'\n",
    "def Collaps_lightcond(num):\n",
    "    if num == 4 or num == 5:\n",
    "        return 11\n",
    "    elif num in [6,8,9]: #unknown\n",
    "        return -1\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Holiday Related\"\n",
    "code_manual[translate_column_names['holiday']][-1] = 'Not Holiday or Unknow date'\n",
    "code_manual[translate_column_names['holiday']][1] = 'Was Holiday'\n",
    "def Collaps_holiday(num):\n",
    "    if num >0:\n",
    "        return 1\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Atmospheric Condition (1)\"\n",
    "code_manual[translate_column_names['atmcond']][1] = 'Clear or Cloudy'\n",
    "code_manual[translate_column_names['atmcond']][2] = 'Precipitation'\n",
    "code_manual[translate_column_names['atmcond']][4] = 'Snow'\n",
    "code_manual[translate_column_names['atmcond']][6] = \"Severe \\\n",
    "Crosswinds, Blowing Sand, Soil, Dirt\",\n",
    "def Collaps_atmcond(num):\n",
    "    if num in [8, 0, 98, 99]: #other or not known\n",
    "        return -1\n",
    "    elif num in [1,10]:\n",
    "        return 1\n",
    "    elif num in [2,12,3]:\n",
    "        return 2\n",
    "    elif num in [6,7]:\n",
    "        return 6\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Hispanic\"\n",
    "code_manual[translate_column_names['hispanic']][10] = 'Is Hispanic'\n",
    "def Collaps_hispanic(num):\n",
    "    if num in [-1,99,0]: #other or not known\n",
    "        return -1\n",
    "    elif num in range(1,7):\n",
    "        return 10\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Race\"\n",
    "code_manual[translate_column_names['race']][30] = 'American Indian or Hawaiian'\n",
    "code_manual[translate_column_names['race']][31] = 'Asian (not Indian)'\n",
    "code_manual[translate_column_names['race']][32] = 'Indian'\n",
    "def Collaps_race(num):\n",
    "    if num in [-1, 0, 98, 99, 97]: #other or not known\n",
    "        return -1\n",
    "    elif num in [3,6]:  \n",
    "        return 30\n",
    "    elif num in [4,5,7,28,38,48,58,68,78]:  \n",
    "        return 31\n",
    "    elif num in [18,19]:  \n",
    "        return 32\n",
    "    return num\n",
    "\n",
    "# Map sex=1 ('male') to sex=0 (for SparseDataFrame efficiency)\n",
    "code_manual[translate_column_names['sex']][0] = 'Male'\n",
    "def Collaps_sex(num):\n",
    "    if num==1:\n",
    "        return 0\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Roadway Function Class\"\n",
    "code_manual[translate_column_names['rfun']][21] = 'Rural-Arterial'\n",
    "code_manual[translate_column_names['rfun']][22] = 'Rural-Collector/Local'\n",
    "code_manual[translate_column_names['rfun']][24] = 'Urban-Arterial'\n",
    "code_manual[translate_column_names['rfun']][25] = 'Urban-Collector/Local'\n",
    "def Collaps_rfun(num):\n",
    "    if num in [1,2,3]:\n",
    "        return 21\n",
    "    elif num in [4,5,6,9]:\n",
    "        return 22\n",
    "    elif num in [11, 12, 13, 14]:\n",
    "        return 24\n",
    "    elif num in [15, 16, 19]:\n",
    "        return 25\n",
    "    elif num == 99: #unknown\n",
    "        return -1\n",
    "    return num\n",
    "\n",
    "\n",
    "# Reduce categories in \"Person Type\"\n",
    "code_manual[translate_column_names['ptype']][1] = 'Driver'\n",
    "code_manual[translate_column_names['ptype']][2] = 'Passenger'\n",
    "code_manual[translate_column_names['ptype']][3] = 'Pedestrian/Cyclist'\n",
    "def Collaps_ptype(num):\n",
    "    if num in [-1,19]: #other or not known\n",
    "        return -1\n",
    "    elif num in [2,3,4]:\n",
    "        return 2\n",
    "    elif num in [5,6,7,8,9,10]:\n",
    "        return 3\n",
    "    return num\n",
    "\n",
    "\n",
    "# Map Mon-Thursday to one bucket, Fri-Sun to another\n",
    "code_manual[translate_column_names['dayofweek']][10] = 'Mon-Thu'\n",
    "code_manual[translate_column_names['dayofweek']][11] = 'Sat-Sun'\n",
    "def Collaps_dayofweek(num):\n",
    "    #if num in [2,3,4,5]:\n",
    "    #    return 10\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply reduction of categories cardinality\n",
    "def Collaps_categoricals(data):\n",
    "    data.lightcond = data.lightcond.apply(Collaps_lightcond )\n",
    "    data.rfun      = data.rfun.apply(Collaps_rfun  )\n",
    "    data.holiday   = data.holiday.apply(Collaps_holiday )\n",
    "    data.atmcond   = data.atmcond.apply(Collaps_atmcond )\n",
    "    data.ptype     = data.ptype.apply(Collaps_ptype )\n",
    "    data.hispanic  = data.hispanic.apply(Collaps_hispanic )\n",
    "    data.race      = data.race.apply(Collaps_race)\n",
    "    data.sex       = data.sex.apply(Collaps_sex)\n",
    "    data.dayofweek = data.dayofweek.apply(Collaps_dayofweek)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map different types of 'unknown' to a single number\n",
    "unknown = {'druginv': [8,9],\n",
    "           'nhs'    : [9],\n",
    "           'reljuncinter': [8,9],\n",
    "           'dayofweek': [-1,9],\n",
    "           'sex'     : [8,9],\n",
    "           'age'     : [-1, 998, 999],\n",
    "           'alcres'  : [95, 96, 97, 98, 99],\n",
    "           'atmcond' : [8, 0, 98, 99],\n",
    "           'druginv' : [-1, 8, 9],\n",
    "           'race'    : [-1, 0, 98, 99, 97],\n",
    "           'hispanic': [-1,99,0],\n",
    "           'ptype'   : [-1,19],\n",
    "           'rfun'    : [-1, 99],\n",
    "           'lightcond': [-1,7,6,8,9],\n",
    "           'acchr'   : [99, -1]\n",
    "          }\n",
    "\n",
    "# collaps all keys for 'unknown' into '-1' value\n",
    "def Collapse_unknowns(data):\n",
    "    for feature in unknown.keys():\n",
    "        try:\n",
    "            data[feature] = data[feature].apply(lambda x: \n",
    "                                                x if x not in unknown[feature] \n",
    "                                                else -1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot encoder where needed\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_categoricals(data, target_name):\n",
    "    categorical_features_list = ['lightcond', 'schlbus', 'druginv', 'nhs', \n",
    "                             'speeding', 'rfun', 'holiday',\n",
    "                           'atmcond', 'heavytruck', 'reljuncinter', \n",
    "                             'ptype', 'dayofweek',\n",
    "                           'hispanic', 'race', 'driverdrowsy', 'sex']\n",
    "    non_categ_features_list = ['age', 'alcres' ]\n",
    "\n",
    "    # Select categorical features\n",
    "    list_f_cat = list(data.keys() & categorical_features_list)\n",
    "    if target_name in list_f_cat:\n",
    "        list_f_cat.remove(target_name)\n",
    "\n",
    "    # One-hot encode\n",
    "    sdf = data.to_sparse(fill_value=0)\n",
    "    list_dummies = [pd.get_dummies(sdf[feature], prefix=feature, prefix_sep=':').to_sparse(fill_value=0) \n",
    "             for feature in list_f_cat]\n",
    "\n",
    "    # Join it all into one sparse dataframe\n",
    "    sdf = sdf.drop(list_f_cat, 1)\n",
    "    for ii in range(len(list_dummies)):\n",
    "        dummy = list_dummies.pop()\n",
    "        sdf[dummy.keys()]=dummy\n",
    "    \n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ANOVA to select features\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth_for_classifier = 5\n",
    "rnd_split = 0                     # random_state for train/test split\n",
    "how_many_features_to_consider = 3   # will consider only n-features at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_score_vs_percentile(data, target_name, return_lots_of_things=False, \n",
    "                                percentiles=[5, 10, 12.5, 15, 20],n_estimators=50,\n",
    "                                decisionTree_maxDepth=None,\n",
    "                                with_Adaboost=True):\n",
    "    # on-hot encoder\n",
    "    sdf = encode_categoricals(data, target_name).to_dense()\n",
    "    print('Size of dataset: %.2e bytes'%size_of_dataframe(sdf))\n",
    "    #train-test split\n",
    "    X, y = sdf.drop(target_name,1), sdf[target_name]\n",
    "    train_features, test_feature, train_label, test_label = train_test_split(\n",
    "            X, y, test_size=0.33, random_state=rnd_split)\n",
    "\n",
    "    # run classification \n",
    "    scoring_vs_percent = {}\n",
    "    print('Percentile: ', end='')\n",
    "    for percen_features in percentiles:\n",
    "        print( percen_features, end=',')\n",
    "        selector = SelectPercentile(f_classif, percentile=percen_features)\n",
    "        tr_train_feat = selector.fit_transform(train_features, train_label)\n",
    "        tr_test_feat  = selector.transform(test_feature)  # do not fit on the test, only on train\n",
    "\n",
    "        if with_Adaboost:\n",
    "            clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=decisionTree_maxDepth),\n",
    "                                 n_estimators=n_estimators)\n",
    "        else:\n",
    "            clf = DecisionTreeClassifier(max_depth=decisionTree_maxDepth)\n",
    "        clf.fit(tr_train_feat, train_label)\n",
    "        scoring_vs_percent[percen_features] = clf.score(tr_test_feat, test_label)\n",
    "\n",
    "    # collect results\n",
    "    df = pd.DataFrame({target_name + '_score' : list(scoring_vs_percent.values())}, \n",
    "                      index = list(scoring_vs_percent.keys()))\n",
    "    print('')\n",
    "    if return_lots_of_things:\n",
    "        features_selected = [d for d, s in zip(train_features.keys(), selector.get_support()) if s ]  \n",
    "        test_predict = clf.predict(tr_test_feat)\n",
    "        return df, clf, features_selected, test_label, test_predict\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to run\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\Luke-Lenovo\\Desktop\\Database2010.txt ...\n",
      "Loading C:\\Users\\Luke-Lenovo\\Desktop\\Database2011.txt ...\n",
      "Loading C:\\Users\\Luke-Lenovo\\Desktop\\Database2012.txt ...\n",
      "Loading C:\\Users\\Luke-Lenovo\\Desktop\\Database2013.txt ...\n",
      "Loading C:\\Users\\Luke-Lenovo\\Desktop\\Database2014.txt ...\n",
      "Number of rows in dataset: 371882\n"
     ]
    }
   ],
   "source": [
    "data = build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[labelsOfInter].applymap(lambda x: -1 if x == '.' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Collapse_unknowns(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf = encode_categoricals(data[['rfun','ptype']], 'ptype').to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, whiten=True).fit(data['rfun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84579542,  0.09766179])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2558681df98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x255c1a91160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp = pca.transform(data)\n",
    "plt.scatter(pp[:,0], pp[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removal of un-knowns: 360466\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "Collaps_categoricals(data)\n",
    "data = Collapse_unknowns(data)\n",
    "\n",
    "# if 'Unknown' is the less frequent entry for a given key, we will remove those entries\n",
    "keys_for_removal_of_unknowns = []\n",
    "for key in data.keys():\n",
    "    ss = data[key].value_counts().argmin() # select less frequent value for this key\n",
    "    if ss == -1:\n",
    "        keys_for_removal_of_unknowns.append(key)\n",
    "\n",
    "for key in keys_for_removal_of_unknowns:\n",
    "    data = data[data[key] != -1]\n",
    "print('Rows after removal of un-knowns:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "result = pd.DataFrame()\n",
    "n_estimators=50\n",
    "labels_to_predict = ['dayofweek','ptype','rfun','lightcond'] #'atmcond','holiday',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 dayofweek. Size of dataset: 1.15e+08 bytes\n",
      "Percentile: 5,10,12.5,15,20,\n",
      "2/4 ptype. Size of dataset: 1.26e+08 bytes\n",
      "Percentile: 5,10,12.5,15,20,\n",
      "3/4 rfun. Size of dataset: 1.24e+08 bytes\n",
      "Percentile: 5,10,12.5,15,20,\n",
      "4/4 lightcond. Size of dataset: 1.24e+08 bytes\n",
      "Percentile: 5,10,12.5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:407: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  kept_ties = ties[:max_feats - mask.sum()]\n",
      "C:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:407: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  kept_ties = ties[:max_feats - mask.sum()]\n",
      "C:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:407: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  kept_ties = ties[:max_feats - mask.sum()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",15,20,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:407: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  kept_ties = ties[:max_feats - mask.sum()]\n"
     ]
    }
   ],
   "source": [
    "# run analysis on all features as target, for different SelectPercentile\n",
    "pickle_filename = \"cest_collapsed_noUnknows_%dRfun_%ddayWeek_2010_3ptype.p\" % (len(set(data.rfun)), len(set(data.dayofweek)) )\n",
    "for target_name in labels_to_predict:\n",
    "    print('%d/%d' % (labels_to_predict.index(target_name)+1, len(labels_to_predict)), target_name, end = '. ')\n",
    "    if result.empty:\n",
    "        result = analyze_score_vs_percentile(data, target_name, n_estimators=n_estimators)\n",
    "    else:\n",
    "        result = result.join( analyze_score_vs_percentile(data, target_name, n_estimators=n_estimators)  )\n",
    "    fname = pickle_filename\n",
    "    if os.path.isfile(fname):\n",
    "        os.remove(fname)\n",
    "    pickle.dump( result, open( fname, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dayofweek_score  ptype_score  rfun_score  lightcond_score\n",
      "20.0         0.179506     0.706592    0.422701         0.561192\n",
      "10.0         0.188359     0.697967    0.407998         0.565345\n",
      "12.5         0.184693     0.701683    0.412950         0.568413\n",
      "5.0          0.188401     0.705323    0.392353         0.562385\n",
      "15.0         0.183264     0.704844    0.413496         0.562940\n",
      "      dayofweek     ptype      rfun  lightcond\n",
      "20.0   0.956792  1.179337  1.165323   1.080589\n",
      "10.0   1.003975  1.164941  1.124788   1.088585\n",
      "12.5   0.984439  1.171143  1.138439   1.094493\n",
      "5.0    1.004199  1.177218  1.081658   1.082887\n",
      "15.0   0.976821  1.176418  1.139945   1.083956\n"
     ]
    }
   ],
   "source": [
    "# normalize score on 'guessing power' (i.e. frequency of most common item)\n",
    "result = pickle.load( open( pickle_filename, \"rb\" ) )\n",
    "print(result)\n",
    "normal_result = pd.DataFrame()\n",
    "for target_name in result.keys():\n",
    "    target_name = target_name.replace('_score', '')\n",
    "    freq = data[target_name].value_counts(normalize = True).iloc[0]\n",
    "    normal_result[target_name] = result[target_name+'_score'].apply(lambda x: x/freq)\n",
    "print(normal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter plot of score and guess_power\n",
    "import bokeh.plotting as bp\n",
    "bp.output_file('Out__Score_vs_GuessingPower.html')\n",
    "colors = ['yellow', 'wheat', 'violet', 'red', 'green',\n",
    "         'sienna', 'seagreen', 'salmon', 'purple', 'PaleTurquoise',\n",
    "         'orange', 'olive', 'navy', 'lime', 'LightSlateGray']\n",
    "\n",
    "score_and_guess = bp.figure(title = 'Adaboost %d estimators, 2012-2014' % n_estimators, \n",
    "                            x_axis_label='Guessing power', \n",
    "                            y_axis_label='Score', y_range=[0,1])\n",
    "\n",
    "colors1 = colors.copy()\n",
    "for target_name in normal_result.keys():\n",
    "    try:\n",
    "        x = normal_result[target_name]\n",
    "        y = result[target_name+'_score']\n",
    "        col = colors1.pop()\n",
    "        s1 = score_and_guess.scatter(x=x,y=y,color=col,size=10,legend=target_name)\n",
    "    except KeyError:\n",
    "        print(target_name, 'not in results: skipping')    \n",
    "        \n",
    "score_and_guess.legend.location = 'bottom_right'\n",
    "score_and_guess.legend.label_text_font_size = '14pt'\n",
    "score_and_guess.xaxis.axis_label_text_font_size = \"22pt\"\n",
    "score_and_guess.xaxis.major_label_text_font_size = '14pt'\n",
    "score_and_guess.yaxis.axis_label_text_font_size = \"22pt\"\n",
    "score_and_guess.yaxis.major_label_text_font_size = '14pt'\n",
    "bp.show(score_and_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bp.output_file('Out__GuessingPower_vs_FeaturePercentile.html')\n",
    "\n",
    "guess_and_perc = bp.figure(title = 'Adaboost %d estimators, 2012-2014' % n_estimators, \n",
    "                x_axis_label='Fetures percentile', \n",
    "                y_axis_label='Guessing power')\n",
    "\n",
    "dummy_ = normal_result.reset_index().sort_values(by='index')\n",
    "x = dummy_['index']\n",
    "\n",
    "colors2 = colors.copy()\n",
    "for target_name in normal_result.keys():\n",
    "    try:\n",
    "        y = normal_result[target_name]\n",
    "        col = colors2.pop()\n",
    "        s1 = guess_and_perc.scatter(x=x,y=y,color=col,size=10,legend=target_name)\n",
    "        s2 = guess_and_perc.line(x=x,y=y,color=col,legend=target_name)\n",
    "    except KeyError:\n",
    "        print(target_name, 'not in results: skipping')\n",
    "\n",
    "guess_and_perc.legend.location = 'bottom_right'\n",
    "guess_and_perc.legend.label_text_font_size = '14pt'\n",
    "guess_and_perc.xaxis.axis_label_text_font_size = \"22pt\"\n",
    "guess_and_perc.xaxis.major_label_text_font_size = '14pt'\n",
    "guess_and_perc.yaxis.axis_label_text_font_size = \"22pt\"\n",
    "guess_and_perc.yaxis.major_label_text_font_size = '14pt'\n",
    "bp.show(guess_and_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Selecting one and checking how good predicitons are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_name = 'rfun'\n",
    "perc = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 1.24e+08 bytes\n",
      "Percentile: 10,"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2fa37a15ae77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m df, clf, features_selected, test_label, test_predict = analyze_score_vs_percentile(data, \n\u001b[0;32m      6\u001b[0m                                         \u001b[0mtarget_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_lots_of_things\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                         percentiles=perc)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-89d6fec663f5>\u001b[0m in \u001b[0;36manalyze_score_vs_percentile\u001b[1;34m(data, target_name, return_lots_of_things, percentiles, n_estimators, decisionTree_maxDepth, with_Adaboost)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecisionTree_maxDepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_train_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mscoring_vs_percent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpercen_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_test_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 sample_weight)\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \"\"\"\n\u001b[0;32m    461\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Luke-Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    517\u001b[0m         estimator_weight = (-1. * self.learning_rate\n\u001b[0;32m    518\u001b[0m                                 * (((n_classes - 1.) / n_classes) *\n\u001b[1;32m--> 519\u001b[1;33m                                    inner1d(y_coding, np.log(y_predict_proba))))\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;31m# Only boost the weights if it will fit again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print classification report for AdaBoost\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df, clf, features_selected, test_label, test_predict = analyze_score_vs_percentile(data, \n",
    "                                        target_name, return_lots_of_things=True, \n",
    "                                        percentiles=perc)\n",
    "\n",
    "print( classification_report(test_label, test_predict))\n",
    "print (confusion_matrix(test_label, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_selectedures_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# score as a function of DecisionTree depth\n",
    "n_estim = 50\n",
    "\n",
    "scores = []\n",
    "depths = [1,3,5,10,20]\n",
    "for depth in depths:\n",
    "    print('%s. Depth:%d' % (target_name, depth))\n",
    "    scores.append( analyze_score_vs_percentile(data, target_name, return_lots_of_things=False, \n",
    "                                    percentiles=perc,n_estimators=n_estim,\n",
    "                                    decisionTree_maxDepth=depth).iloc[0] )\n",
    "\n",
    "    \n",
    "bp.output_file('Out__%s_Score_vs_Depth.html'%target_name)\n",
    "\n",
    "score_vs_depth = bp.figure(title = 'Adaboost %d estimators, 2012-2014, %d%% features' % (n_estimators, perc[0]), \n",
    "                x_axis_label='Decision tree depth for %s' % (target_name), \n",
    "                y_axis_label='Score', y_range=[0,1])\n",
    "\n",
    "score_vs_depth.scatter(x=depths, y=scores, color='navy', size=10)\n",
    "bp.show(score_vs_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One tree, print rules \n",
    "\n",
    "1. Select maxdepth=5, 20% features, No Adaboost\n",
    "2. Print rules in JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 1.26e+08 bytes\n",
      "Percentile: 20,\n"
     ]
    }
   ],
   "source": [
    "target_name = 'ptype'\n",
    "df, clf, features_selected, test_label, test_predict = analyze_score_vs_percentile(data, \n",
    "                                                         target_name, \n",
    "                                                         return_lots_of_things=True, \n",
    "                                                         percentiles=[20],\n",
    "                                                         decisionTree_maxDepth=5,\n",
    "                                                         with_Adaboost=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.73      0.87      0.79     71180\n",
      "        2.0       0.69      0.62      0.65     38002\n",
      "        3.0       0.35      0.01      0.01      9772\n",
      "\n",
      "avg / total       0.69      0.72      0.68    118954\n",
      "\n",
      "[[61853  9285    42]\n",
      " [14420 23495    87]\n",
      " [ 8373  1328    71]]\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print( classification_report(test_label, test_predict))\n",
    "print (confusion_matrix(test_label, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel_keys =  features_selected               # list of keys in the 20% percentile\n",
    "labels = [ code_manual[translate_column_names[target_name]][value] \n",
    "          for value in sorted(list(set(test_label))) ] # list of labels for category\n",
    "r = rules(clf, sel_keys, labels, simple_leaf_string=True)\n",
    "fname = '.\\\\ShowcaseApp\\\\static\\\\structure.json'\n",
    "if os.path.isfile(fname):\n",
    "        os.remove(fname)\n",
    "with open(fname, 'w') as f:\n",
    "    f.write(json.dumps(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = 'rfun'\n",
    "data[tar].hist(bins=max(data[tar])+2)\n",
    "print('Level1: ', 1./len(set(data[tar])))\n",
    "print('Level2: ', data[tar].value_counts().iloc[0]/len(data) )\n",
    "print('Level3: class. score')\n",
    "\n",
    "#proxy_predict =  26* np.ones(test_label.shape)\n",
    "#print( classification_report(test_label, proxy_predict))\n",
    "#print (confusion_matrix(test_label, proxy_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old strategy: select n features and analyze with those only\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- find best set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def run_analysis(clean_dataset, target_name, returnClassifier=False):\n",
    "    # Separate into train_features, train_label and test_feature, test_label\n",
    "    \n",
    "    X, y = clean_dataset.drop(target_name,1), clean_dataset[target_name]\n",
    "    \n",
    "    train_features, test_feature, train_label, test_label = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=rnd_split)\n",
    "    \n",
    "    # Train decision tree\n",
    "    clf = AdaBoostClassifier(n_estimators=300,\n",
    "                             base_estimator = DecisionTreeClassifier(max_depth = max_depth_for_classifier)\n",
    "                             )\n",
    "    clf.fit(train_features, train_label)\n",
    "    y_predicted = clf.predict(test_feature)\n",
    "     \n",
    "    if returnClassifier:\n",
    "        return clf.score(test_feature, test_label), clf, test_label, y_predicted\n",
    "    return clf.score(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations as comb\n",
    "how_many_features_to_consider = 2   # will consider only n-features at once\n",
    "output = {}\n",
    "target_name = 'dayofweek'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ww = ''   # dummy variables, just for printing out the progress of the analysis\n",
    "for sel_feat in comb(labelsOfInter, how_many_features_to_consider):\n",
    "    features = list(sel_feat)\n",
    "   \n",
    "    if target_name in features:\n",
    "        features = features.remove(target_name)\n",
    "        continue\n",
    "    if str(features) in output.keys():\n",
    "        continue\n",
    "        \n",
    "    #is it a new word?\n",
    "    if features[0] != ww:\n",
    "        print('\\n-- Selecting', features[0], ' and')\n",
    "        ww = features[0]\n",
    "    print(features[1:], end=\", \")\n",
    "    \n",
    "    # There are many keys in the dataset for one feature\n",
    "    # because we passed the one-hot encoder.\n",
    "    #  we want to select all keys corresponding to\n",
    "    #  the given feature\n",
    "    sel_keys = []\n",
    "    for feat in features:\n",
    "        for key in data.keys():\n",
    "            if key.startswith(feat):\n",
    "                sel_keys.append(key)\n",
    "    sel_keys.append(target_name)\n",
    "    clean = data[sel_keys]#.copy()\n",
    "    #clean = clean.to_sparse()\n",
    "\n",
    "    output[str(features)] = run_analysis(clean, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = pd.Series(output)\n",
    "pp = pp.sort_values(ascending=False)[:10]\n",
    "\n",
    "\n",
    "#plot the top 10\n",
    "pl = pp.to_frame('score')\n",
    "pl = pl.reset_index()\n",
    "pl.columns = ['feat', 'score']\n",
    "pl['rel_score'] = pl.score.apply(lambda x: x/max(pl.score)) \n",
    "#pickle.dump( pl, open( \"Output-supp%d.p\" % size_of_dataframe(sdf), \"wb\" ) )\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot top results\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.charts.attributes import CatAttr\n",
    "from bokeh.plotting import show, output_file\n",
    "#output_notebook()\n",
    "output_file(\"barchart.html\", title=\"results\")\n",
    "\n",
    "#TOOLS = \"pan,wheel_zoom,box_zoom,reset,resize,save\"\n",
    "#fig = figure(tools=TOOLS, toolbar_location=\"left\", logo=\"grey\", plot_width=120)\n",
    "\n",
    "\n",
    "p = Bar(pl, label=CatAttr(columns=['feat'], sort=False),\n",
    "        values='rel_score', \n",
    "        title=\"Scores per set of features\",\n",
    "        color=\"blue\",\n",
    "        ylabel=\"score (relative to max score)\",\n",
    "        xlabel='',\n",
    "        plot_width = 900)\n",
    "p.y_range = Range1d(round(pl.rel_score.iloc[-1],3),pl.rel_score.iloc[1])\n",
    "show(p)\n",
    "\n",
    "\n",
    "#Bar(pl).io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the tree\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#label_dictionary = 'Sun Mon Tue Wed Thu Fri Sat'.split()\n",
    "\n",
    "def rules(clf, features, labels, node_index=0, simple_leaf_string=True):\n",
    "    \"\"\"Structure of rules in a fit decision tree classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : DecisionTreeClassifier\n",
    "        A tree that has already been fit.\n",
    "\n",
    "    features, labels : lists of str\n",
    "        The names of the features and labels, respectively.\n",
    "\n",
    "    \"\"\"\n",
    "    node = {}\n",
    "    if clf.tree_.children_left[node_index] == -1:  # indicates leaf\n",
    "        count_labels = zip(clf.tree_.value[node_index, 0], labels)\n",
    "        node['name'] = ', '.join(('{} of {}'.format(int(count), label)\n",
    "                                  for count, label in count_labels))\n",
    "        if simple_leaf_string:\n",
    "            node['name'] = simplify_string(node['name'], labels)\n",
    "    else:\n",
    "        feature = features[clf.tree_.feature[node_index]]\n",
    "        threshold = clf.tree_.threshold[node_index]\n",
    "        node['name'] = '{} > {}'.format(feature, threshold)\n",
    "        left_index = clf.tree_.children_left[node_index]\n",
    "        right_index = clf.tree_.children_right[node_index]\n",
    "        node['children'] = [rules(clf, features, labels, right_index, simple_leaf_string),\n",
    "                            rules(clf, features, labels, left_index, simple_leaf_string)]\n",
    "    return node\n",
    "\n",
    "def simplify_string(st, labels):\n",
    "    #st = '772 of Sun, 838 of Mon, 862 of Tue, 899 of Wed, 919 of Thu, 1024 of Fri, 994 of Sat'\n",
    "    st = st.split(', ')\n",
    "    nums = [ int(entry.split()[0]) for entry in st ]\n",
    "    pred_day = labels[nums.index(max(nums))]\n",
    "    return pred_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the tree for the winning set of features\n",
    "#-------------\n",
    "\n",
    "# retrieve winning set of features\n",
    "ss = pl.feat.iloc[0]\n",
    "for char in ['[', ']', \"'\"]:\n",
    "    ss = ss.replace(char, '')\n",
    "ff = ss.split(',')\n",
    "\n",
    "sel_keys = []\n",
    "for feat in ff:\n",
    "    feat = feat.strip()\n",
    "    for key in data.keys():\n",
    "        if key.startswith(feat):\n",
    "            sel_keys.append(key)\n",
    "sel_keys.append(target_name)\n",
    "\n",
    "# re-do analysis and catch classifier\n",
    "clean = data[sel_keys]\n",
    "num_, classfr, y_true, y_predicted = run_analysis(clean, target_name, returnClassifier=True)\n",
    "\n",
    "# print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print( classification_report(y_true, y_predicted, target_names=label_dictionary)  )\n",
    "print (confusion_matrix(y_true, y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if target_name in sel_keys:\n",
    "    sel_keys.remove(target_name)\n",
    "\n",
    "sel_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = rules(classfr, sel_keys, label_dictionary, simple_leaf_string=True)\n",
    "with open('rules_maxdepth%d.json'%(max_depth_for_classifier), 'w') as f:\n",
    "    f.write(json.dumps(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
